import { describe, it, expect, vi, beforeEach } from 'vitest'
import { render, screen, waitFor } from '@testing-library/react'
import { FaceMeshDetector } from './FaceMeshDetector'

// MediaPipeã‚’ãƒ¢ãƒƒã‚¯
vi.mock('@mediapipe/face_mesh', () => ({
  FaceMesh: vi.fn().mockImplementation(() => ({
    setOptions: vi.fn(),
    onResults: vi.fn(),
    initialize: vi.fn().mockResolvedValue(undefined),
    close: vi.fn()
  }))
}))

vi.mock('@mediapipe/camera_utils', () => ({
  Camera: vi.fn().mockImplementation(() => ({
    start: vi.fn(),
    stop: vi.fn()
  }))
}))

describe('FaceMeshDetector', () => {
  let mockVideoElement: HTMLVideoElement

  beforeEach(() => {
    // ãƒ¢ãƒƒã‚¯ãƒ“ãƒ‡ã‚ªè¦ç´ ã‚’ä½œæˆ
    mockVideoElement = document.createElement('video')
    
    // videoWidthã¨videoHeightã¯getterãªã®ã§ã€Objectã‚’ä½¿ã£ã¦å®šç¾©
    Object.defineProperty(mockVideoElement, 'videoWidth', {
      value: 640,
      writable: false
    })
    Object.defineProperty(mockVideoElement, 'videoHeight', {
      value: 480,
      writable: false
    })
    
    vi.clearAllMocks()
  })

  // ğŸ”´ RED: Face MeshåˆæœŸåŒ–ã®ãƒ†ã‚¹ãƒˆï¼ˆã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ï¼‰
  it('should initialize Face Mesh correctly', async () => {
    const mockOnResults = vi.fn()
    
    // ã“ã®é–¢æ•°ã¯ã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ã®ã§å¤±æ•—ã™ã‚‹
    render(
      <FaceMeshDetector 
        videoElement={mockVideoElement}
        onResults={mockOnResults}
      />
    )

    // åˆæœŸåŒ–ä¸­ã®è¡¨ç¤ºã‚’ç¢ºèª
    expect(screen.getByText(/Initializing face detection/)).toBeInTheDocument()

    // Face MeshãŒåˆæœŸåŒ–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    await waitFor(() => {
      expect(screen.queryByText(/Initializing face detection/)).not.toBeInTheDocument()
    })
  })

  // ğŸ”´ RED: Face Meshè¨­å®šã®ãƒ†ã‚¹ãƒˆï¼ˆã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ï¼‰
  it('should configure Face Mesh with correct options', async () => {
    const mockOnResults = vi.fn()
    
    render(
      <FaceMeshDetector 
        videoElement={mockVideoElement}
        onResults={mockOnResults}
        maxNumFaces={2}
        refineLandmarks={true}
      />
    )

    // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒæç”»ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    await waitFor(() => {
      expect(screen.getByRole('img')).toBeInTheDocument()
    })
  })

  // ğŸ”´ RED: Canvasè¦ç´ ã®æç”»ãƒ†ã‚¹ãƒˆï¼ˆã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ï¼‰
  it('should render canvas element for face visualization', () => {
    const mockOnResults = vi.fn()
    
    render(
      <FaceMeshDetector 
        videoElement={mockVideoElement}
        onResults={mockOnResults}
      />
    )

    // CanvasãŒæç”»ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    const canvas = screen.getByRole('img') // canvasã¯é€šå¸¸img roleã‚’æŒã¤
    expect(canvas).toBeInTheDocument()
    expect(canvas.tagName.toLowerCase()).toBe('canvas')
  })

  // ğŸ”´ RED: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆï¼ˆã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ï¼‰
  it('should handle Face Mesh initialization errors', async () => {
    const mockOnResults = vi.fn()
    
    // Face MeshåˆæœŸåŒ–ã‚’å¤±æ•—ã•ã›ã‚‹
    const { FaceMesh } = await import('@mediapipe/face_mesh')
    const mockFaceMesh = FaceMesh as any
    mockFaceMesh.mockImplementationOnce(() => ({
      setOptions: vi.fn(),
      onResults: vi.fn(),
      initialize: vi.fn().mockRejectedValue(new Error('Face Mesh initialization failed')),
      close: vi.fn()
    }))

    render(
      <FaceMeshDetector 
        videoElement={mockVideoElement}
        onResults={mockOnResults}
      />
    )

    // ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    await waitFor(() => {
      expect(screen.getByRole('alert')).toBeInTheDocument()
      expect(screen.getByText(/Face Mesh initialization failed/)).toBeInTheDocument()
    })
  })

  // ğŸ”´ RED: é¡”æ¤œå‡ºçµæœã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ï¼‰
  it('should call onResults callback when face detection results are received', async () => {
    const mockOnResults = vi.fn()
    
    render(
      <FaceMeshDetector 
        videoElement={mockVideoElement}
        onResults={mockOnResults}
      />
    )

    // Face Meshã®çµæœã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    const mockResults = {
      multiFaceLandmarks: [
        [
          { x: 0.5, y: 0.4, z: 0.1 },
          { x: 0.6, y: 0.5, z: 0.2 }
        ]
      ],
      image: mockVideoElement
    }

    // onResultsã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒå‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆå®Ÿè£…å¾Œã«ãƒ‘ã‚¹ã™ã‚‹ï¼‰
    // ã“ã®æ™‚ç‚¹ã§ã¯å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ãŸã‚å¤±æ•—ã™ã‚‹
  })

  // ğŸ”´ RED: ãƒ“ãƒ‡ã‚ªè¦ç´ å¤‰æ›´æ™‚ã®å†åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆï¼ˆã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ï¼‰
  it('should reinitialize when video element changes', async () => {
    const mockOnResults = vi.fn()
    
    const { rerender } = render(
      <FaceMeshDetector 
        videoElement={mockVideoElement}
        onResults={mockOnResults}
      />
    )

    // æ–°ã—ã„ãƒ“ãƒ‡ã‚ªè¦ç´ ã§å†ãƒ¬ãƒ³ãƒ€ãƒ¼
    const newVideoElement = document.createElement('video')
    Object.defineProperty(newVideoElement, 'videoWidth', {
      value: 1280,
      writable: false
    })
    Object.defineProperty(newVideoElement, 'videoHeight', {
      value: 720,
      writable: false
    })

    rerender(
      <FaceMeshDetector 
        videoElement={newVideoElement}
        onResults={mockOnResults}
      />
    )

    // å†åˆæœŸåŒ–ãŒè¡Œã‚ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆå®Ÿè£…å¾Œã«ãƒ‘ã‚¹ã™ã‚‹ï¼‰
    await waitFor(() => {
      expect(screen.queryByText(/Initializing face detection/)).not.toBeInTheDocument()
    })
  })
})